{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Torchvision + BERT**"
      ],
      "metadata": {
        "id": "7ouMahENhCmO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hORMinonfPGA",
        "outputId": "f99d271d-762c-4394-c101-65b7bd37cb58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_dataset.csv')\n",
        "print(df.shape)\n",
        "print(df['Review Image'][0])\n",
        "\n",
        "# Function to update the image path\n",
        "def update_image_path(old_path):\n",
        "    # Split the path using os.path.basename, handling both Windows and Unix-like paths\n",
        "    filename = os.path.basename(old_path.replace('\\\\', '/'))  # Handle Windows backslashes\n",
        "    # Construct the new path (update this to your new directory path)\n",
        "    new_path = f'/content/drive/MyDrive/hotel images/{filename}'\n",
        "    return new_path\n",
        "\n",
        "# Apply the function to the 'Review Image' column\n",
        "df['Review Image'] = df['Review Image'].apply(update_image_path)\n",
        "\n",
        "# Save the updated dataset\n",
        "df.to_csv('/content/drive/MyDrive/updated_cleaneddataset.csv', index=False)\n",
        "\n",
        "print(\"Image paths updated successfully.\")\n",
        "print(df['Review Image'][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ZP2WBKsEJA",
        "outputId": "8d9ad36b-22c6-4eb2-cc85-279e82b0c073"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1678, 4)\n",
            "E:\\OneDrive\\Desktop\\sem7\\BTP\\project_dataset\\Hotel_images\\Hotel_images\\hotel images\\d1_1.jpeg\n",
            "Image paths updated successfully.\n",
            "/content/drive/MyDrive/hotel images/d1_1.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/updated_cleaneddataset.csv')\n",
        "print(df.shape)\n",
        "print(df['Review Image'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TkKpZ7EsLYL",
        "outputId": "13310fd8-9d95-4ed7-ab7e-d96d722e52ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1678, 4)\n",
            "/content/drive/MyDrive/hotel images/d1_1.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-Fold Cross Validation**"
      ],
      "metadata": {
        "id": "kgBrS35phJ3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define the combined model\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, text_dim, image_dim, combined_dim):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.text_fc = nn.Linear(text_dim, combined_dim)\n",
        "        self.image_fc = nn.Linear(image_dim, combined_dim)\n",
        "        self.fc = nn.Linear(combined_dim * 2, 5)  # Output layer for 5 classes\n",
        "\n",
        "    def forward(self, text_features, image_features):\n",
        "        text_out = self.text_fc(text_features)\n",
        "        image_out = self.image_fc(image_features)\n",
        "        combined = torch.cat((text_out, image_out), dim=1)\n",
        "        output = self.fc(combined)\n",
        "        return output\n",
        "\n",
        "# Define the custom dataset class\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, images, labels, tokenizer, transform=None):\n",
        "        self.texts = texts\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.image_feature_size = 150528  # 224x224x3 (assuming image features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Process text\n",
        "        text = self.texts[idx]\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)  # Ensure text is a string\n",
        "\n",
        "        # Tokenize the text input\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Extract text features using the BERT model\n",
        "        with torch.no_grad():\n",
        "            text_features = self.bert_model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0)).last_hidden_state.mean(dim=1)\n",
        "        text_features = text_features.squeeze(0)\n",
        "\n",
        "        # Process image\n",
        "        image_path = self.images[idx]\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            image_features = image.view(-1)\n",
        "        except FileNotFoundError:\n",
        "            # Handle cases where the image file is missing or invalid\n",
        "            print(f\"Warning: Image not found for index {idx}, using default zero image\")\n",
        "            image_features = torch.zeros(self.image_feature_size)\n",
        "\n",
        "        # Get the label and convert it to a tensor\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return text_features, image_features, label\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define dimensions\n",
        "text_dim = 768  # BERT output dimension\n",
        "image_dim = 150528  # 224x224x3\n",
        "combined_dim = 256\n",
        "\n",
        "# Training function with progress percentage\n",
        "def train_model(train_loader, model, criterion, optimizer, scheduler, device, grad_clip_value):\n",
        "    model.train()\n",
        "    total_batches = len(train_loader)\n",
        "    for batch_idx, (text_features, image_features, labels) in enumerate(train_loader):\n",
        "        text_features = text_features.to(device)\n",
        "        image_features = image_features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(text_features.float(), image_features.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Apply gradient clipping to avoid instability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step(loss)  # Update learning rate based on loss\n",
        "\n",
        "        # Calculate progress percentage\n",
        "        progress = (batch_idx + 1) / total_batches * 100\n",
        "        print(f\"Training Loss: {loss.item():.4f} | Progress: {progress:.2f}%\")\n",
        "\n",
        "# Predict function\n",
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for text_features, image_features, _ in dataloader:\n",
        "            text_features = text_features.to(device)\n",
        "            image_features = image_features.to(device)\n",
        "            output = model(text_features.float(), image_features.float())\n",
        "            preds = torch.argmax(output, dim=1)  # Get class indices\n",
        "            predictions.extend(preds.cpu().tolist())  # Convert to list and extend\n",
        "    return predictions\n",
        "\n",
        "# Calculate accuracy function\n",
        "def calculate_accuracy(predictions, labels):\n",
        "    correct = sum(1 for pred, actual in zip(predictions, labels) if pred == actual)\n",
        "    total = len(labels)\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Stratified Cross-Validation\n",
        "def stratified_cross_val(csv_file, tokenizer, transform, device, n_splits=5):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(csv_file, encoding='ISO-8859-1')\n",
        "    texts = data['Review Text'].tolist()\n",
        "    images = data['Review Image'].tolist()\n",
        "    labels = LabelEncoder().fit_transform(data['Rating'].tolist())\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store fold results\n",
        "    fold_accuracies = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(texts, labels)):\n",
        "        print(f\"\\nFold {fold+1}/{n_splits}\")\n",
        "\n",
        "        # Split data based on current fold indices\n",
        "        train_texts = [texts[i] for i in train_idx]\n",
        "        test_texts = [texts[i] for i in test_idx]\n",
        "        train_images = [images[i] for i in train_idx]\n",
        "        test_images = [images[i] for i in test_idx]\n",
        "        train_labels = [labels[i] for i in train_idx]\n",
        "        test_labels = [labels[i] for i in test_idx]\n",
        "\n",
        "        # Create DataLoaders\n",
        "        train_dataset = ReviewDataset(train_texts, train_images, train_labels, tokenizer, transform)\n",
        "        test_dataset = ReviewDataset(test_texts, test_images, test_labels, tokenizer, transform)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  #  batch size\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  #  batch size\n",
        "\n",
        "        # Initialize model, criterion, and optimizer for each fold\n",
        "        model = CombinedModel(text_dim, image_dim, combined_dim)\n",
        "        model.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
        "\n",
        "        # Learning rate scheduler (ReduceLR on plateau)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "        # Gradient clipping value\n",
        "        grad_clip_value = 1.0  # To handle exploding gradients\n",
        "\n",
        "        # Train the model on the current fold\n",
        "        train_model(train_loader, model, criterion, optimizer, scheduler, device, grad_clip_value)\n",
        "\n",
        "        # Evaluate the model\n",
        "        predictions = predict(model, test_loader, device)\n",
        "        fold_accuracy = calculate_accuracy(predictions, test_labels)\n",
        "        fold_accuracies.append(fold_accuracy)\n",
        "\n",
        "    # Print average accuracy across all folds\n",
        "    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "    print(f\"\\nAverage Accuracy across {n_splits} folds: {avg_accuracy:.2f}%\")\n",
        "\n",
        "# Example usage\n",
        "device = torch.device('cuda')  # Specify GPU\n",
        "stratified_cross_val('/content/drive/MyDrive/updated_cleaneddataset.csv', tokenizer, transform, device)\n"
      ],
      "metadata": {
        "id": "8wqqYfD4fQYk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}