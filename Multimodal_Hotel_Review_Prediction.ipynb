{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Torchvision + BERT**"
      ],
      "metadata": {
        "id": "ZwpY_BgigKoC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMDgjJpk5gD2"
      },
      "outputs": [],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_dataset.csv')\n",
        "print(df.shape)\n",
        "print(df['Review Image'][0])\n",
        "\n",
        "# Function to update the image path\n",
        "def update_image_path(old_path):\n",
        "    # Split the path using os.path.basename, handling both Windows and Unix-like paths\n",
        "    filename = os.path.basename(old_path.replace('\\\\', '/'))  # Handle Windows backslashes\n",
        "    # Construct the new path (update this to your new directory path)\n",
        "    new_path = f'/content/drive/MyDrive/hotel images/{filename}'\n",
        "    return new_path\n",
        "\n",
        "# Apply the function to the 'Review Image' column\n",
        "df['Review Image'] = df['Review Image'].apply(update_image_path)\n",
        "\n",
        "# Save the updated dataset\n",
        "df.to_csv('/content/drive/MyDrive/updated_cleaneddataset.csv', index=False)\n",
        "\n",
        "print(\"Image paths updated successfully.\")\n",
        "print(df['Review Image'][0])\n"
      ],
      "metadata": {
        "id": "1GWQ0DUeK7ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/updated_cleaneddataset.csv')\n",
        "print(df.shape)\n",
        "print(df['Review Image'][0])"
      ],
      "metadata": {
        "id": "bZ1h36x3LTzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define the combined model\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, text_dim, image_dim, combined_dim):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.text_fc = nn.Linear(text_dim, combined_dim)\n",
        "        self.image_fc = nn.Linear(image_dim, combined_dim)\n",
        "        self.fc = nn.Linear(combined_dim * 2, 5)  # Output layer for 5 classes\n",
        "\n",
        "    def forward(self, text_features, image_features):\n",
        "        text_out = self.text_fc(text_features)\n",
        "        image_out = self.image_fc(image_features)\n",
        "        combined = torch.cat((text_out, image_out), dim=1)\n",
        "        output = self.fc(combined)\n",
        "        return output\n",
        "\n",
        "# Define the custom dataset class\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, images, labels, tokenizer, transform=None):\n",
        "        self.texts = texts\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Process text\n",
        "        text = self.texts[idx]\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)  # Ensure text is a string\n",
        "\n",
        "        # Tokenize the text input\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Extract text features using the BERT model\n",
        "        with torch.no_grad():\n",
        "            text_features = self.bert_model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0)).last_hidden_state.mean(dim=1)\n",
        "        text_features = text_features.squeeze(0)\n",
        "\n",
        "        # Process image\n",
        "        image_path = self.images[idx]\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            image_features = image.view(-1)\n",
        "        except FileNotFoundError:\n",
        "            # Handle cases where the image file is missing or invalid\n",
        "            print(f\"Warning: Image not found for index {idx}, using default zero image\")\n",
        "            image_features = torch.zeros(self.image_feature_size)  # Assuming image_feature_size is defined\n",
        "\n",
        "        # Get the label and convert it to a tensor\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return text_features, image_features, label\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define dimensions\n",
        "text_dim = 768  # BERT output dimension\n",
        "image_dim = 150528  # 224x224x3\n",
        "combined_dim = 256\n",
        "\n",
        "# Training function\n",
        "# Training function with progress percentage\n",
        "def train_model(train_loader, model, criterion, optimizer, scheduler, device, grad_clip_value, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_batches = len(train_loader)\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (text_features, image_features, labels) in enumerate(train_loader):\n",
        "            text_features = text_features.to(device)\n",
        "            image_features = image_features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(text_features.float(), image_features.float())\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Apply gradient clipping to avoid instability\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step(loss)  # Update learning rate based on loss\n",
        "\n",
        "            # Calculate progress percentage\n",
        "            progress = (batch_idx + 1) / total_batches * 100\n",
        "            running_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{total_batches}] - Training Loss: {loss.item():.4f} | Progress: {progress:.2f}%\")\n",
        "\n",
        "        # Log the average loss for the epoch\n",
        "        avg_loss = running_loss / total_batches\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Predict function\n",
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for text_features, image_features, _ in dataloader:\n",
        "            text_features = text_features.to(device)\n",
        "            image_features = image_features.to(device)\n",
        "            output = model(text_features.float(), image_features.float())\n",
        "            preds = torch.argmax(output, dim=1)  # Get class indices\n",
        "            predictions.extend(preds.cpu().tolist())  # Convert to list and extend\n",
        "    return predictions\n",
        "\n",
        "# Calculate accuracy function\n",
        "def calculate_accuracy(predictions, labels):\n",
        "    correct = sum(1 for pred, actual in zip(predictions, labels) if pred == actual)\n",
        "    total = len(labels)\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Train-test split and model evaluation\n",
        "def train_test_model(csv_file, tokenizer, transform, device):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(csv_file, encoding='ISO-8859-1')\n",
        "    texts = data['Review Text'].tolist()\n",
        "    images = data['Review Image'].tolist()\n",
        "    labels = LabelEncoder().fit_transform(data['Rating'].tolist())\n",
        "\n",
        "    # Split the dataset into training and test sets (80:20)\n",
        "    train_texts, test_texts, train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "        texts, images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_dataset = ReviewDataset(train_texts, train_images, train_labels, tokenizer, transform)\n",
        "    test_dataset = ReviewDataset(test_texts, test_images, test_labels, tokenizer, transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  #  batch size\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  #  batch size\n",
        "\n",
        "    # Initialize model, criterion, and optimizer\n",
        "    model = CombinedModel(text_dim, image_dim, combined_dim)\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
        "\n",
        "    # Learning rate scheduler (ReduceLR on plateau)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    # Gradient clipping value\n",
        "    grad_clip_value = 1.0  # To handle exploding gradients\n",
        "\n",
        "    # Train the model\n",
        "    # Modify the number of epochs in the train_test_model function call\n",
        "    train_model(train_loader, model, criterion, optimizer, scheduler, device, grad_clip_value, num_epochs=10)  # Specify the number of epochs\n",
        "\n",
        "\n",
        "    # Evaluate the model\n",
        "    predictions = predict(model, test_loader, device)\n",
        "    accuracy = calculate_accuracy(predictions, test_labels)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Example usage\n",
        "device = torch.device('cuda')  # Specify GPU\n",
        "train_test_model('/content/drive/MyDrive/updated_cleaneddataset.csv', tokenizer, transform, device)\n"
      ],
      "metadata": {
        "id": "yaGiHMmxGLeU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}